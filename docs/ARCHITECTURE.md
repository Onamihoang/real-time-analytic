# Ki·∫øn Tr√∫c H·ªá Th·ªëng Real-Time Analytics

## T·ªïng Quan

ƒê√¢y l√† m·ªôt n·ªÅn t·∫£ng ph√¢n t√≠ch d·ªØ li·ªáu th·ªùi gian th·ª±c (Real-Time Analytics Platform) s·ª≠ d·ª•ng ki·∫øn tr√∫c Lambda ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu streaming. H·ªá th·ªëng thu th·∫≠p, x·ª≠ l√Ω v√† tr·ª±c quan h√≥a d·ªØ li·ªáu gi√° cryptocurrency theo th·ªùi gian th·ª±c.

## S∆° ƒê·ªì Ki·∫øn Tr√∫c T·ªïng Quan

```plantuml
@startuml
!define RECTANGLE class

skinparam componentStyle rectangle
skinparam backgroundColor #FEFEFE
skinparam component {
    BackgroundColor<<orchestration>> LightBlue
    BackgroundColor<<streaming>> LightGreen
    BackgroundColor<<analytics>> LightYellow
    BackgroundColor<<visualization>> LightPink
    BackgroundColor<<storage>> LightGray
}

package "Orchestration Layer" <<orchestration>> {
    [Airflow\nScheduler] as airflow
    [Airflow\nWebserver] as airflow_web
}

package "Streaming Layer" <<streaming>> {
    [Kafka Broker\n:9092] as kafka
    [Zookeeper\n:2181] as zk
    [Producer\nDAGs] as producer
}

package "Analytics Engine" <<analytics>> {
    [Druid Router\n:8888] as router
    [Druid Broker\n:8082] as broker
    [Druid Coordinator\n:8081] as coordinator
    [Druid Historical\n:8083] as historical
    [Druid MiddleManager\n:8091] as middlemanager
}

package "Storage Layer" <<storage>> {
    database "PostgreSQL\n:5432" as postgres
    database "Redis" as redis
    storage "Local Storage\n/opt/shared" as storage
}

package "Visualization Layer" <<visualization>> {
    [Apache Superset\n:8088] as superset
}

' Orchestration connections
airflow --> producer : schedule every 1min
producer --> kafka : produce messages

' Streaming connections
kafka --> zk : coordination
kafka --> middlemanager : consume stream

' Analytics connections
middlemanager --> coordinator : register tasks
coordinator --> postgres : metadata
coordinator --> zk : cluster state
broker --> postgres : metadata
broker --> zk : cluster state
historical --> postgres : metadata
historical --> storage : read segments
middlemanager --> storage : write segments
router --> broker : route queries
router --> coordinator : route management

' Visualization connections
superset --> router : SQL queries
airflow_web --> airflow : monitor

' User interactions
actor User
User --> airflow_web : monitor workflows
User --> superset : view dashboards
User --> router : query data

@enduml
```

## C√°c Layer Ch√≠nh

### 1. **Orchestration Layer** (T·∫ßng ƒêi·ªÅu Ph·ªëi)
**C√¥ng ngh·ªá:** Apache Airflow 2.2.5

**Vai tr√≤:**
- L·∫≠p l·ªãch v√† th·ª±c thi c√°c DAG (Directed Acyclic Graph)
- T·ª± ƒë·ªông h√≥a vi·ªác sinh d·ªØ li·ªáu demo
- Qu·∫£n l√Ω workflow v√† dependencies

**Components:**
- **Airflow Scheduler**: L·∫≠p l·ªãch ch·∫°y DAGs theo cron expression
- **Airflow Webserver**: UI ƒë·ªÉ monitor v√† qu·∫£n l√Ω workflows
- **DAG Demo**: Ch·∫°y m·ªói ph√∫t, sinh 4 messages (BTC, ETH, DOT, BTT)

**Port:** 3000 (mapped t·ª´ 8080 internal)

---

### 2. **Streaming Layer** (T·∫ßng Streaming)
**C√¥ng ngh·ªá:** Apache Kafka + Zookeeper

**Vai tr√≤:**
- Message broker cho real-time data streaming
- Decoupling gi·ªØa producers v√† consumers
- Buffer d·ªØ li·ªáu v·ªõi kh·∫£ nƒÉng replay

**Components:**
- **Kafka Broker**: Nh·∫≠n v√† l∆∞u tr·ªØ messages trong topic "demo"
- **Zookeeper**: Qu·∫£n l√Ω cluster state v√† coordination
- **Producer**: Sinh d·ªØ li·ªáu cryptocurrency gi·∫£ l·∫≠p

**Message Format:**
```json
{
    "data_id": 150,
    "name": "BTC",
    "timestamp": 1645270401
}
```

**Ports:**
- Kafka: 9092 (internal), 29092 (external)
- Zookeeper: 2181 (internal), 22181 (external)

---

### 3. **Analytics Engine** (T·∫ßng Ph√¢n T√≠ch)
**C√¥ng ngh·ªá:** Apache Druid 0.22.1+

**Vai tr√≤:**
- OLAP database cho time-series data
- Real-time ingestion v√† indexing
- High-performance analytical queries
- Columnar storage v·ªõi compression

**Components:**

#### **Druid Router** (:8888)
- Entry point cho t·∫•t c·∫£ requests
- Route queries ƒë·∫øn Broker
- Route management requests ƒë·∫øn Coordinator

#### **Druid Broker** (:8082)
- Query execution engine
- Merge results t·ª´ Historical v√† real-time segments
- Query optimization v√† caching

#### **Druid Coordinator** (:8081)
- Qu·∫£n l√Ω data availability
- Segment assignment ƒë·∫øn Historical nodes
- Cluster management UI

#### **Druid Historical** (:8083)
- L∆∞u tr·ªØ immutable segments
- Serve queries cho historical data
- Load segments t·ª´ deep storage (/opt/shared)

#### **Druid MiddleManager** (:8091, :8100-8105)
- Ingest data t·ª´ Kafka
- T·∫°o real-time segments
- Execute indexing tasks
- Hand-off segments cho Historical

**Druid Extensions:**
- `druid-kafka-indexing-service`: Kafka integration
- `druid-datasketches`: Approximate algorithms
- `druid-histogram`: Histogram calculations
- `druid-multi-stage-query`: Complex query support

---

### 4. **Storage Layer** (T·∫ßng L∆∞u Tr·ªØ)

#### **PostgreSQL** (:5432)
- Metadata storage cho Druid
- L∆∞u tr·ªØ segment metadata, task info, rules
- Docker image: postgres:14.1-alpine

#### **Redis**
- Caching layer (optional)
- Session management
- Fast key-value store

#### **Local File System** (/opt/shared)
- Deep storage cho Druid segments
- Shared volume gi·ªØa MiddleManager v√† Historical
- Production n√™n d√πng S3/GCS/HDFS

---

### 5. **Visualization Layer** (T·∫ßng Tr·ª±c Quan H√≥a)
**C√¥ng ngh·ªá:** Apache Superset 1.4.1

**Vai tr√≤:**
- Business Intelligence platform
- T·∫°o dashboards v√† charts
- SQL Lab cho ad-hoc queries
- Data exploration

**Connection:**
- SQLAlchemy URI: `druid://broker:8082/druid/v2/sql/`
- Query Druid th√¥ng qua SQL interface

**Port:** 8088

---

## Tech Stack Summary

### Backend & Processing
| Layer | Technology | Version |
|-------|-----------|---------|
| Workflow Orchestration | Apache Airflow | 2.2.5 |
| Message Streaming | Apache Kafka | 5.2.0 |
| Coordination | Apache Zookeeper | Latest |
| Analytics Engine | Apache Druid | 0.22.1+ |
| Programming Language | Python | 3.9 |

### Data Storage
| Component | Technology | Version |
|-----------|-----------|---------|
| Metadata Database | PostgreSQL | 14.1-alpine |
| Airflow Database | SQLite | Default |
| Caching | Redis | Latest |
| Deep Storage | Local FS | /opt/shared |

### Visualization & BI
| Component | Technology | Version |
|-----------|-----------|---------|
| Dashboard | Apache Superset | 1.4.1 |
| Database Connector | SQLAlchemy | Latest |

### Infrastructure
| Component | Technology | Version |
|-----------|-----------|---------|
| Containerization | Docker | Latest |
| Orchestration | Docker Compose | 3.8 |

### Python Libraries
```
kafka-python==2.0.2
psycopg2==2.9.3
numpy==1.24.2
pandas==1.5.3
```

---

## Port Mapping Reference

| Service | Internal Port | External Port | Purpose |
|---------|---------------|---------------|---------|
| Airflow | 8080 | 3000 | Workflow UI |
| Kafka | 9092 | 29092 | Message Broker |
| Zookeeper | 2181 | 22181 | Coordination |
| PostgreSQL | 5432 | 5432 | Metadata DB |
| Druid Router | 8888 | 8888 | Unified API |
| Druid Broker | 8082 | 8082 | Query Engine |
| Druid Coordinator | 8081 | 8081 | Management UI |
| Druid Historical | 8083 | 8083 | Storage Node |
| Druid MiddleManager | 8091 | 8091 | Task Execution |
| Superset | 8088 | 8088 | BI Dashboard |

---

## Deployment

### Kh·ªüi ƒë·ªông h·ªá th·ªëng:
```bash
docker-compose up -d
```

### Truy c·∫≠p c√°c UI:
- **Airflow**: http://localhost:3000
- **Druid Console**: http://localhost:8888
- **Superset**: http://localhost:8088
- **Druid Coordinator**: http://localhost:8081

### Ki·ªÉm tra logs:
```bash
docker-compose logs -f [service-name]
```

---

## Production Considerations

### Hi·ªán t·∫°i (Demo):
- ‚úÖ SequentialExecutor (Airflow)
- ‚úÖ SQLite metadata (Airflow)
- ‚úÖ Local file storage (Druid)
- ‚úÖ Single Kafka broker
- ‚úÖ No replication

### Production n√™n c√≥:
- üîß CeleryExecutor ho·∫∑c KubernetesExecutor
- üîß PostgreSQL/MySQL cho Airflow metadata
- üîß S3/GCS/Azure Blob cho Druid deep storage
- üîß Kafka cluster v·ªõi replication ‚â• 3
- üîß Multiple Druid nodes cho high availability
- üîß Monitoring (Prometheus + Grafana)
- üîß Authentication & Authorization
- üîß SSL/TLS encryption
- üîß Auto-scaling capabilities

---

## Tham Kh·∫£o

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Druid Documentation](https://druid.apache.org/docs/latest/design/)
- [Apache Superset Documentation](https://superset.apache.org/docs/intro)
